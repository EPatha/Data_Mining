#Step 1: Import Dataset

import pandas as pd
from IPython.display import display

# Load the dataset
df = pd.read_csv('heart_2020_cleaned.csv')

# Tampilkan beberapa baris pertama dari data untuk memastikan data sudah diimpor dengan benar
print("First 5 rows of the dataset:")
display(df.head())

# Lihat nama kolom yang ada di dalam dataset
print("Columns in the dataset:")
print(df.columns)

#Step 2: Handle Missing Values

# Drop or fill missing values
df = df.dropna()

# Tampilkan jumlah baris setelah menghapus missing values
print("Number of rows after dropping missing values:", df.shape[0])

#Step 3: Transform and Normalize

from sklearn.preprocessing import StandardScaler

# Pilih fitur numerik yang akan dinormalisasi
numerical_features = ['MentalHealth', 'PhysicalHealth', 'SleepTime']
scaler = StandardScaler()

# Normalisasi fitur numerik yang sudah dipilih
df[numerical_features] = scaler.fit_transform(df[numerical_features])

# Tampilkan data setelah normalisasi untuk memastikan berhasil
print("Data after normalization:")
display(df[numerical_features].head(10))

#Step 4: Encoding

from sklearn.preprocessing import LabelEncoder

# Pilih fitur yang akan digunakan
features = ['Smoking', 'AlcoholDrinking', 'MentalHealth', 'PhysicalHealth', 'SleepTime']
target = 'HeartDisease'

# Encoding untuk variabel kategori (Smoking dan AlcoholDrinking)
label_encoder = LabelEncoder()
df['Smoking'] = label_encoder.fit_transform(df['Smoking'])
df['AlcoholDrinking'] = label_encoder.fit_transform(df['AlcoholDrinking'])
df['HeartDisease'] = label_encoder.fit_transform(df['HeartDisease'])

# Tampilkan DataFrame dengan format tabel yang rapi
print("Data after encoding:")
display(df[features + [target]].head(10))

#Step 5: Build Models

# Pisahkan fitur (X) dan target (y)
X = df[features]
y = df[target]

# Print beberapa data X dan y
print("Features (X):")
display(X.head(10))
print("Target (y):")
display(y.head(10))

#Estimasi
# Estimasi bisa dilakukan dengan model regresi atau analisis statistik.
# Contoh: menggunakan regresi logistik
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Split data menjadi training dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inisialisasi model regresi logistik
model = LogisticRegression()

# Latih model
model.fit(X_train, y_train)

# Tampilkan koefisien model
print("Model coefficients:", model.coef_)

#Prediction
# Buat prediksi pada data test
predictions = model.predict(X_test)

# Tampilkan hasil prediksi
print("Predictions on test data:")
display(pd.DataFrame({'Actual': y_test, 'Predicted': predictions}))

#Klasifikasi
from sklearn.metrics import classification_report

# Tampilkan laporan klasifikasi
print("Classification Report:")
print(classification_report(y_test, predictions, zero_division=0))
#Zero_divison bila data itu merusak target atau tak di target manapun.

#Clustering (bila dataset tidak berlabel)
from sklearn.cluster import KMeans

# Contoh: menggunakan KMeans untuk klustering
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X)

# Tampilkan hasil klustering
df['Cluster'] = kmeans.labels_
print("Data with cluster labels:")
display(df.head(10))

#Association Learning
!pip install mlxtend
# Pastikan untuk menginstal mlxtend sebelum menjalankan ini
from mlxtend.frequent_patterns import apriori, association_rules

# Contoh: menggunakan algoritma Apriori untuk pembelajaran asosiasi
# Pertama, kita perlu mengonversi DataFrame ke format yang sesuai
# Misalnya, gunakan pd.get_dummies untuk mengonversi variabel kategorikal ke format one-hot
basket = pd.get_dummies(df[features + [target]], columns=features)

# Dapatkan aturan asosiasi
frequent_itemsets = apriori(basket, min_support=0.05, use_colnames=True)
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)

# Tampilkan beberapa aturan asosiasi
print("Association Rules:")
display(rules.head(10))
